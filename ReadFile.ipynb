{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "311e5e44",
   "metadata": {},
   "source": [
    "# Extract text and images from pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7ee72",
   "metadata": {},
   "source": [
    "<b>Imports</b> \n",
    "\n",
    "To use pytesseract (on Windows): <br>\n",
    "conda install -c conda-forge pytesseract <br>\n",
    "conda install -c conda-forge tesseract <br>\n",
    "\n",
    " <br>\n",
    "\n",
    "To use pdf2image: <br>\n",
    "conda install -c conda-forge pdf2image <br>\n",
    "conda install -c conda-forge poppler <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ddf8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "#should already have\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c8a99",
   "metadata": {},
   "source": [
    "Here, the path to tesseract and tessdata need to be specified for the program to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a116f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\annut\\miniconda3\\envs\\Tehisintellekt\\Library\\bin\\tesseract.exe'\n",
    "os.environ['TESSDATA_PREFIX'] = r'C:\\Users\\annut\\miniconda3\\envs\\Tehisintellekt\\share\\tessdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23970025",
   "metadata": {},
   "source": [
    "Some parameters need to pe specified in order to use the program and improve its quality.\n",
    "\n",
    "<b>path</b> - this is where the found images will be saved\n",
    "\n",
    "<b>filename</b> - location + name of the pdf file\n",
    "\n",
    "<b>language</b> - the language in which the pdf is in (est for Estonian, eng for English and so on: https://www.labnol.org/code/19899-google-translate-languages)\n",
    "\n",
    "<b>page_numbers</b> - whether the pdf pages have page numbers at the end (True) or not (False)\n",
    "\n",
    "<b>skip_images_without_text</b> - whether the program should skip images that are on pages without any text (True) or not (False)\n",
    "\n",
    "<b>skip_slides</b> - slide numbers to skip (example: \"1-3, 5\", slides 1, 2, 3 and 5 will be skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc7c6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"images/\"\n",
    "filename = 'example2.pdf'\n",
    "language = 'est'\n",
    "page_numbers = True\n",
    "skip_images_without_text = True\n",
    "skip_slides = \"1, 10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672da660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://stackoverflow.com/questions/57249273/how-to-detect-paragraphs-in-a-text-document-image-for-a-non-consistent-text-stru\n",
    "def getParagraphs(image):\n",
    "    paragraphs = []\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=12)\n",
    "\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        rect = [x, y, w, h]\n",
    "        paragraphs.append(rect)\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "\n",
    "def getContent(filename, lang, skipped):\n",
    "    text = \"\"\n",
    "    pictures = []\n",
    "    picture_count = 0\n",
    "    \n",
    "    images = convert_from_path(filename)\n",
    "    pattern = r\"[a-zöüõäA-ZÖÄÜÕ][a-zöüõäA-ZÖÄÜÕ]+[,\\/-:;?!]*\"\n",
    "    \n",
    "    for j in range(len(images)):\n",
    "        if j+1 not in skipped:\n",
    "            image = images[j]\n",
    "            paragraphs = getParagraphs(image)\n",
    "\n",
    "            for i in range(len(paragraphs)-1, -1, -1):\n",
    "\n",
    "                if i == 0 and page_numbers:\n",
    "                        break\n",
    "\n",
    "                p = paragraphs[i]\n",
    "                x, y, w, h = p[0], p[1], p[2], p[3]\n",
    "                segment = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "                unique_colors = set(segment.getdata())\n",
    "\n",
    "                if len(unique_colors) > 15000:\n",
    "                    if len(paragraphs) == 1 and skip_images_without_text:\n",
    "                        break\n",
    "                    else:\n",
    "                        picturefilename = \"Picture_\" + str(picture_count) + \".png\"\n",
    "                        cv2.imwrite(path + picturefilename, np.array(segment))\n",
    "                        text += \"(Vaata: Pilt \" + str(picture_count) + \") \"\n",
    "                        picture_count +=1\n",
    "                        pictures.append(picturefilename)\n",
    "\n",
    "                else: \n",
    "                    extracted_text = pytesseract.image_to_string(segment, lang=lang)\n",
    "                    sentence = extracted_text.strip().replace('\\n', \" \")\n",
    "                    raw_text = re.findall(pattern, sentence)\n",
    "\n",
    "                    if len(raw_text) > 0:\n",
    "                        text += ' '.join(raw_text).replace(\";\", \"\").replace(\":\", \"\").capitalize() + \". \"                        \n",
    "    return text, pictures\n",
    "\n",
    "def getSkippedSlides(skip):\n",
    "    skipped = []\n",
    "    if skip == \"\":\n",
    "        return skipped\n",
    "    slides = skip.replace(\" \", \"\").split(\",\")\n",
    "    \n",
    "    for slide in slides:\n",
    "        if \"-\" in slide:\n",
    "            no = slide.split(\"-\")\n",
    "            for i in range(int(no[0]), int(no[1])+1):\n",
    "                skipped.append(i)\n",
    "        else:\n",
    "            skipped.append(int(slide))\n",
    "    return skipped\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a427fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped = getSkippedSlides(skip_slides)\n",
    "text, pictures = getContent(filename, language, skipped)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6cf067",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
