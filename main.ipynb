{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports\n",
    "Please note that some imports are somewhat hacky to get to work and require some tinkering."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-05-20T21:28:21.863267100Z",
     "start_time": "2023-05-20T21:28:21.850672600Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline # Handles summarization\n",
    "import requests # Handles translation using the DeepL API\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Global variables and constants\n",
    "The DeepL API key is used for the translation API. If the API key becomes invalid for some reason, you can generate your own API key following the instructions at https://www.deepl.com/docs-api."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# At this time of writing this (20.05.2023), the API had 450k characters still unused. Please keep this in mind and use the provided key responsibly.\n",
    "DEEPL_API_KEY = '898523e2-0911-71ea-8d45-3e60991d2130:fx'\n",
    "DEEPL_BASE_URL = 'https://api-free.deepl.com'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T21:28:21.880322400Z",
     "start_time": "2023-05-20T21:28:21.858259300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# A short description of the summarization logic\n",
    "Originally, the plan was to simply summarize the provided text natively in the language it was provided. There are plenty of examples of this available, such as the open-source Reddit bot \"autotldr\", which has a similar function.\n",
    "\n",
    "Problems rose when it was determined that lots of slideshows have only bullet points, which isn't compatible with the style other similar projects use. Other projects use a pattern, where they extract the important sentences from the provided text without editing it. This falls apart with ours.\n",
    "\n",
    "To bypass this problem, the `SummarizerPipeline` from the huggingface `transformers` library is used. By translating the source text to English and then summarizing it, we can bypass many of the issues that arise from the traditional summarization methods. This also makes it trivial to add additional languages, in fact by default all DeepL supported languages should theoretically be able to be summarized properly. Keep in mind that this is untested functionality and no guarantees are provided."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def translate_text(text: str, target_lang: str ='EN-GB', source_lang: Optional[str] = None) -> tuple[str, str]:\n",
    "    \"\"\"This function returns a tuple of (source_lang, translated_text).\"\"\"\n",
    "    # Build the URL for the translation service\n",
    "    url = f\"{DEEPL_BASE_URL}/v2/translate\"\n",
    "    # Build the payload\n",
    "    payload = { 'text': [text], 'target_lang': target_lang }\n",
    "    # In case a manual source language is set, we should pass it along. Otherwise, DeepL will handle it for us\n",
    "    if source_lang is not None:\n",
    "        payload[source_lang] = source_lang\n",
    "    # Headers\n",
    "    headers = { 'Authorization': f\"DeepL-Auth-Key {DEEPL_API_KEY}\" }\n",
    "    # Send the request\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    json_response = response.json()\n",
    "    # See the DeepL docs for the exact JSON format\n",
    "    return json_response['translations'][0]['detected_source_language'], json_response['translations'][0]['text']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T21:28:21.889315Z",
     "start_time": "2023-05-20T21:28:21.877326200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def summarize_text(text: str, language: Optional[str] = None) -> str:\n",
    "    \"\"\"This functions returns a summary of the provided text. If the source language is known, pass it in the `language`\n",
    "        argument for a more accurate translation.\"\"\"\n",
    "    # Get the translated text with its corresponding language\n",
    "    source_lang, translated_text = translate_text(text, source_lang=language)\n",
    "    # Get the amount of tokens in the new text. The max length will be 50% of that.\n",
    "    # This is a simple solution because we don't need to be 100% accurate.\n",
    "    token_count = len(translated_text.split(\" \"))\n",
    "    half_token_count = token_count // 2\n",
    "    # Summarize the text\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summarized_text_en = summarizer(translated_text, min_length=10, max_length=half_token_count)[0][\"summary_text\"]\n",
    "    # Get back the original language\n",
    "    _, returnable_text = translate_text(summarized_text_en, target_lang=source_lang, source_lang='EN')\n",
    "    return returnable_text\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-20T21:28:21.909315300Z",
     "start_time": "2023-05-20T21:28:21.890316400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
