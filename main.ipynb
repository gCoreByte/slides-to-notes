{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "Please note that some imports are somewhat hacky to get to work and require some tinkering.\n",
    "\n",
    "To use pytesseract: <br>\n",
    "conda install -c conda-forge pytesseract <br>\n",
    "conda install -c conda-forge tesseract <br>\n",
    "\n",
    "To use pdf2image: <br>\n",
    "conda install -c conda-forge pdf2image <br>\n",
    "conda install -c conda-forge poppler <br>\n",
    "\n",
    "To use reportlab: <br>\n",
    "conda install reportlab <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T17:48:19.461124100Z",
     "start_time": "2023-05-21T17:48:19.429978600Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline # Handles summarization\n",
    "import requests # Handles translation using the DeepL API\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "import PIL\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import os\n",
    "\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Image\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.enums import TA_CENTER, TA_JUSTIFY\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from os.path import isfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global variables and constants\n",
    "The DeepL API key is used for the translation API. If the API key becomes invalid for some reason, you can generate your own API key following the instructions at https://www.deepl.com/docs-api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T17:48:26.975837500Z",
     "start_time": "2023-05-21T17:48:19.451003900Z"
    }
   },
   "outputs": [],
   "source": [
    "# At this time of writing this (20.05.2023), the API had 450k characters still unused. \n",
    "#Please keep this in mind and use the provided key responsibly.\n",
    "DEEPL_API_KEY = '898523e2-0911-71ea-8d45-3e60991d2130:fx'\n",
    "DEEPL_BASE_URL = 'https://api-free.deepl.com'\n",
    "path = 'images/' #where the images will be saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Here, the path to tesseract and tessdata need to be specified for the program to work. </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Users\\annut\\miniconda3\\envs\\Tehisintellekt\\Library\\bin\\tesseract.exe' #r'path to tesseract.exe'\n",
    "os.environ['TESSDATA_PREFIX'] = r'C:\\Users\\annut\\miniconda3\\envs\\Tehisintellekt\\share\\tessdata/' #r'path to /tessdata/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slides to text and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source: https://stackoverflow.com/questions/57249273/how-to-detect-paragraphs-in-a-text-document-image-for-a-non-consistent-text-stru\n",
    "def getParagraphs(image, iterat):\n",
    "    '''This function return the locations of paragraphs on a slide found by using dilation'''\n",
    "    \n",
    "    if iterat == 1:\n",
    "        iterations = 7\n",
    "    elif iterat == 2:\n",
    "        iterations = 10\n",
    "    else:\n",
    "        iterations = 12\n",
    "    \n",
    "    paragraphs = []\n",
    "    image_np = np.array(image)\n",
    "    \n",
    "    gray = cv2.cvtColor(image_np, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "    dilate = cv2.dilate(thresh, kernel, iterations=iterations)\n",
    "\n",
    "    cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "    for c in cnts:\n",
    "        x,y,w,h = cv2.boundingRect(c)\n",
    "        rect = [x, y, w, h]\n",
    "        paragraphs.append(rect)\n",
    "    \n",
    "    return paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getContent(filename, lang, skipped, iterat):\n",
    "    '''This function extracts text and pictures from slides based on the detected paragraphs and returns them \n",
    "    (text as a string and pictures as an array of the filenames). The prorgam uses regex to only extract proper \n",
    "    text and not for example any functions.'''\n",
    "    \n",
    "    text = \"\"\n",
    "    pictures = []\n",
    "    picture_count = 0\n",
    "    pattern = r\"[a-zöüõäA-ZÖÄÜÕ][a-zöüõäA-ZÖÄÜÕ]+[,\\/-:;?!]*\"\n",
    "    \n",
    "    images = convert_from_path(filename)\n",
    "    \n",
    "    #Skanning slides one by one.\n",
    "    for j in range(len(images)):\n",
    "        if j+1 not in skipped:\n",
    "            image = images[j]\n",
    "            paragraphs = getParagraphs(image, iterat)\n",
    "\n",
    "            for i in range(len(paragraphs)-1, -1, -1):\n",
    "\n",
    "                if i == 0 and page_numbers:\n",
    "                        break\n",
    "\n",
    "                p = paragraphs[i]\n",
    "                x, y, w, h = p[0], p[1], p[2], p[3]\n",
    "                segment = image.crop((x, y, x + w, y + h))\n",
    "\n",
    "                #If the cropped image contains a lot of colors, it is most likely a picture, not text\n",
    "                unique_colors = set(segment.getdata())\n",
    "                if len(unique_colors) > 15000:\n",
    "                    if len(paragraphs) == 1 and skip_images_without_text:\n",
    "                        break\n",
    "                    else:\n",
    "                        picturefilename = \"Picture_\" + str(picture_count) + \".png\"\n",
    "                        segment.save(path + picturefilename)\n",
    "                        text += \"(Vaata: Pilt \" + str(picture_count) + \") \"\n",
    "                        picture_count +=1\n",
    "                        pictures.append(picturefilename)\n",
    "\n",
    "                else: \n",
    "                    extracted_text = pytesseract.image_to_string(segment, lang=lang)\n",
    "                    sentence = extracted_text.strip().replace('\\n', \" \")\n",
    "                    raw_text = re.findall(pattern, sentence)\n",
    "\n",
    "                    if len(raw_text) > 0:\n",
    "                        text += ' '.join(raw_text).replace(\";\", \"\").replace(\":\", \"\").capitalize() + \". \"                        \n",
    "    \n",
    "    return text, pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSkippedSlides(skip):\n",
    "    '''This function turns the input for skipped slides to a usable form and returns the slide numbers as an array.'''\n",
    "    skipped = []\n",
    "    if skip == \"\":\n",
    "        return skipped\n",
    "    slides = skip.replace(\" \", \"\").split(\",\")\n",
    "    \n",
    "    for slide in slides:\n",
    "        if \"-\" in slide:\n",
    "            no = slide.split(\"-\")\n",
    "            for i in range(int(no[0]), int(no[1])+1):\n",
    "                skipped.append(i)\n",
    "        else:\n",
    "            skipped.append(int(slide))\n",
    "    return skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A short description of the summarization logic\n",
    "Originally, the plan was to simply summarize the provided text natively in the language it was provided. There are plenty of examples of this available, such as the open-source Reddit bot \"autotldr\", which has a similar function.\n",
    "\n",
    "Problems rose when it was determined that lots of slideshows have only bullet points, which isn't compatible with the style other similar projects use. Other projects use a pattern, where they extract the important sentences from the provided text without editing it. This falls apart with ours.\n",
    "\n",
    "To bypass this problem, the `SummarizerPipeline` from the huggingface `transformers` library is used. By translating the source text to English and then summarizing it, we can bypass many of the issues that arise from the traditional summarization methods. This also makes it trivial to add additional languages, in fact by default all DeepL supported languages should theoretically be able to be summarized properly. Keep in mind that this is untested functionality and no guarantees are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T17:48:26.990377400Z",
     "start_time": "2023-05-21T17:48:26.977388600Z"
    }
   },
   "outputs": [],
   "source": [
    "def translate_text(text: str, target_lang: str ='EN-GB', source_lang: Optional[str] = None) -> Tuple[str, str]:\n",
    "    \"\"\"This function returns a tuple of (source_lang, translated_text).\"\"\"\n",
    "    # Build the URL for the translation service\n",
    "    url = f\"{DEEPL_BASE_URL}/v2/translate\"\n",
    "    # Build the payload\n",
    "    payload = { 'text': [text], 'target_lang': target_lang }\n",
    "    # In case a manual source language is set, we should pass it along. Otherwise, DeepL will handle it for us\n",
    "    if source_lang is not None:\n",
    "        payload[source_lang] = source_lang\n",
    "    # Headers\n",
    "    headers = { 'Authorization': f\"DeepL-Auth-Key {DEEPL_API_KEY}\" }\n",
    "    # Send the request\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    json_response = response.json()\n",
    "    # See the DeepL docs for the exact JSON format\n",
    "    return json_response['translations'][0]['detected_source_language'], json_response['translations'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T17:48:27.018926700Z",
     "start_time": "2023-05-21T17:48:26.995040Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_text(text: str, language: Optional[str] = None, test=False) -> str:\n",
    "    \"\"\"This functions returns a summary of the provided text. If the source language is known, pass it in the `language`\n",
    "        argument for a more accurate translation. For testing, please set test to True and pass in English text only.\"\"\"\n",
    "    # Get the translated text with its corresponding language\n",
    "    source_lang = 'EN'\n",
    "    translated_text = text\n",
    "    if not test:\n",
    "        source_lang, translated_text = translate_text(text, source_lang=language)\n",
    "    # Summarize the text\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    summarized_text_en = summarizer(translated_text, max_length=1024, min_length=500, do_sample=False, truncation=True)[0]['summary_text']\n",
    "    # Get back the original language\n",
    "    returnable_text = summarized_text_en\n",
    "    if not test:\n",
    "        _, returnable_text = translate_text(summarized_text_en, target_lang=source_lang, source_lang='EN')\n",
    "    return returnable_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the final PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateTimeStamp() -> str:\n",
    "    date_time = datetime.fromtimestamp(time())\n",
    "    timestamp = date_time.strftime(\"%d-%m-%Y %H:%M\")\n",
    "    return timestamp\n",
    "\n",
    "\n",
    "def getNewFileWidth(filename:str, definedheight:int) -> int:\n",
    "    \"\"\"This method calculates and returns a new width for an image, given the image file name and the desired heigth, while preserving aspect ratio.\"\"\"    \n",
    "    im = PIL.Image.open(filename)\n",
    "    w, h = im.size\n",
    "    im.close()\n",
    "\n",
    "    ratio = w / h\n",
    "    newwidth = int(definedheight * ratio)\n",
    "    \n",
    "    return newwidth\n",
    "\n",
    "\n",
    "def createTitleParagraph(content:str, styles) -> Paragraph:\n",
    "    paragraph = Paragraph(text=content, style=styles[\"Title\"])\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "def createTextParagraph(content:str, styles) -> Paragraph:\n",
    "    paragraph = Paragraph(text=content, style=styles[\"NormalJustified\"])\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "def createTimestampParagraph(content:str, styles, lang:str) -> Paragraph:\n",
    "\n",
    "    if lang == \"eng\":\n",
    "        content = f\"Generated {content}\"\n",
    "    elif lang == \"est\":\n",
    "        content = f\"Genereeritud {content}\"\n",
    "    else:\n",
    "        #default to eng\n",
    "        content = f\"Generated {content}\"\n",
    "\n",
    "    paragraph = Paragraph(text=content, style=styles[\"Heading5\"])\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "def createImageReferenceParagraph(content:str, styles, lang:str) -> Paragraph:\n",
    "\n",
    "    content = content.strip()\n",
    "    content = content[:len(content) - 4]\n",
    "    contents = content.split(\"_\")\n",
    "\n",
    "    number = contents[len(contents) - 1]\n",
    "    \n",
    "    if lang == \"eng\":\n",
    "        content = f\"Image {number}\"\n",
    "    elif lang == \"est\":\n",
    "        content = f\"Pilt {number}\"\n",
    "    else:\n",
    "        #default to eng\n",
    "        content = f\"Image {number}\"\n",
    "\n",
    "    paragraph = Paragraph(text=content, style=styles[\"Reference\"])\n",
    "\n",
    "    return paragraph\n",
    "\n",
    "\n",
    "def createImageParagraph(filename:str, desiredheight:int) -> Image:\n",
    "\n",
    "    w = getNewFileWidth(filename=filename, definedheight=desiredheight)\n",
    "\n",
    "    image = Image(filename=filename, \n",
    "                  height=desiredheight,\n",
    "                  width=w,\n",
    "                  hAlign=\"CENTER\",\n",
    "                  lazy=2)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "def createPDF(filename:str, lang:str, header:str, text:str, imagefiles:list = None) -> bool:\n",
    "    \"\"\"Creates a PDF file with the provided inputs. List of images can be an empty list. Returns true if PDF file was created sucessfully.\"\"\"\n",
    "    \n",
    "    timestamp = generateTimeStamp()\n",
    "    \n",
    "    #make sure lang variable is good\n",
    "    lang = str(lang).lower()\n",
    "    if lang == \"eng\" or lang == \"en\":\n",
    "        lang = \"eng\"\n",
    "    if lang == \"est\" or lang == \"ee\" or lang == \"et\":\n",
    "        lang = \"est\"\n",
    "\n",
    "    #create document\n",
    "    document = SimpleDocTemplate(\n",
    "        filename=filename,\n",
    "        pagesize=A4,\n",
    "        rightMargin=50, leftMargin=50,\n",
    "        topMargin=50, bottomMargin=50,\n",
    "    )\n",
    "\n",
    "    #get some default styles\n",
    "    styles = getSampleStyleSheet()\n",
    "\n",
    "    #define some of my own styles\n",
    "    styles.add(ParagraphStyle(name='Reference',\n",
    "                                parent=styles['Normal'],\n",
    "                                fontSize=12,\n",
    "                                spaceBefore=2,\n",
    "                                spaceAfter=12,\n",
    "                                alignment=TA_CENTER))\n",
    "    \n",
    "    styles.add(ParagraphStyle(name='NormalJustified',\n",
    "                                parent=styles['Normal'],\n",
    "                                fontSize=12,\n",
    "                                spaceAfter=50,\n",
    "                                alignment=TA_JUSTIFY))\n",
    "    \n",
    "    flowables = []\n",
    "    \n",
    "    #add the title\n",
    "    flowables.append(createTitleParagraph(content=header, styles=styles))\n",
    "\n",
    "    #add time created\n",
    "    flowables.append(createTimestampParagraph(content=timestamp, styles=styles, lang=lang))\n",
    "\n",
    "    #add summary\n",
    "    flowables.append(createTextParagraph(content=text, styles=styles))\n",
    "\n",
    "    if not imagefiles is None or len(imagefiles) > 0:\n",
    "        #add all image files with their references, if they exist\n",
    "        for imagefilename in imagefiles:\n",
    "            if isfile(path + imagefilename):\n",
    "                flowables.append(createImageParagraph(filename=path+imagefilename, desiredheight=150))\n",
    "                flowables.append(createImageReferenceParagraph(content=imagefilename, styles=styles, lang=lang))\n",
    "\n",
    "        #build the document\n",
    "        document.build(flowables=flowables)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-21T17:54:06.067900200Z",
     "start_time": "2023-05-21T17:54:06.025080Z"
    }
   },
   "source": [
    "## Run program\n",
    "\n",
    "Here the code can be tested. Before running the program, make sure You have set the variables in the cell after \"Global variables and constants\" to match your system.\n",
    "\n",
    "<b>filename</b> - location + name of the pdf file<br>\n",
    "<b>newfile</b> - the generated pdf name\n",
    "<b>language</b> - the language in which the pdf is in (est for Estonian, eng for English and so on: https://www.labnol.org/code/19899-google-translate-languages)<br>\n",
    "<b>page_numbers</b> - whether the pdf pages have page numbers at the end (True) or not (False)<br>\n",
    "<b>skip_images_without_text</b> - whether the program should skip images that are on pages without any text (True) or not (False)<br>\n",
    "<b>skip_slides</b> - slide numbers to skip (example: \"1-3, 5\", slides 1, 2, 3 and 5 will be skipped)<br>\n",
    "<b>spacing</b> - the estimation of the spacing between rows on slide (1 = little, 2 = medium, 3 = a lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"\"\n",
    "newfile = \"\"\n",
    "language = \"\"\n",
    "page_numbers = True\n",
    "skip_images_without_text = True\n",
    "skip_slides = \"\"\n",
    "header = \"\"\n",
    "spacing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skipped = getSkippedSlides(skip_slides)\n",
    "\n",
    "#Convert slides to text and pictures\n",
    "#text, pictures = getContent(filename, language, skipped, spacing)\n",
    "\n",
    "#Generate summary\n",
    "#summary = summarize_text(text, test=True)\n",
    "\n",
    "#Generate pdf\n",
    "#createPDF(filename=newfile, lang=language, header=header, text=text, imagefiles=pictures)\n",
    "\n",
    "#print(\"The \", header, \" notes were saved to file \", newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1\n",
    "The slides used in this example are from the course Universum kõigile (LTTO.00.019). They are made by Laurits Leedjärv and are optimal for our program, because they contain comprehensive sentences. We are not going to skip any slides since we want all the pictures from the slides to be in our notes. These slides do not have page numbers. We have also shortened the slideshow down to 14 slides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  Astronoomia ajalugu  notes were saved to file  notes1.pdf\n"
     ]
    }
   ],
   "source": [
    "filename = 'example1.pdf'\n",
    "newfile = 'notes1.pdf'\n",
    "language = 'est'\n",
    "page_numbers = False\n",
    "skip_images_without_text = False\n",
    "skip_slides = \"\"\n",
    "header = \"Astronoomia ajalugu\"\n",
    "spacing = 1\n",
    "\n",
    "skipped = getSkippedSlides(skip_slides)\n",
    "\n",
    "#Convert slides to text and pictures\n",
    "text, pictures = getContent(filename, language, skipped, spacing)\n",
    "\n",
    "#Generate summary\n",
    "summary = summarize_text(text, test=False)\n",
    "\n",
    "#Generate pdf\n",
    "createPDF(filename=newfile, lang=language, header=header, text=summary, imagefiles=pictures)\n",
    "\n",
    "print(\"The\", header, \"notes were saved to file\", newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2\n",
    "The slides used in this example are from the course Tehisintellekt (LTAT.01.003). They are made by Mark Fišel and are pretty ok for our program, but since they mostly contain bullet points the generated notes are not as comprehensive as they could be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 1024, but you input_length is only 483. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=241)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The  Mängud  notes were saved to file  notes2.pdf\n"
     ]
    }
   ],
   "source": [
    "filename = 'example2.pdf'\n",
    "newfile = 'notes2.pdf'\n",
    "language = 'est'\n",
    "page_numbers = True\n",
    "skip_images_without_text = True\n",
    "skip_slides = \"1, 71\"\n",
    "header = \"Mängud\"\n",
    "spacing = 2\n",
    "\n",
    "skipped = getSkippedSlides(skip_slides)\n",
    "\n",
    "#Convert slides to text and pictures\n",
    "text, pictures = getContent(filename, language, skipped, spacing)\n",
    "\n",
    "#Generate summary\n",
    "summary = summarize_text(text, test=False)\n",
    "\n",
    "#Generate pdf\n",
    "createPDF(filename=newfile, lang=language, header=header, text=summary, imagefiles=pictures)\n",
    "\n",
    "print(\"The\", header, \"notes were saved to file\", newfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3\n",
    "The slides used in this example are from the course Tehisintellekt (LTAT.01.003). They are made by Mark Fišel and are not optimal for our program since the slides contain very little text, but we still wanted to show how our program handels slides like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 1024, but you input_length is only 344. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=172)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Masinõpe ja andmestikud notes were saved to file notes3.pdf\n"
     ]
    }
   ],
   "source": [
    "filename = 'example3.pdf'\n",
    "newfile = 'notes3.pdf'\n",
    "language = 'est'\n",
    "page_numbers = True\n",
    "skip_images_without_text = True\n",
    "skip_slides = \"\"\n",
    "header = \"Masinõpe ja andmestikud\"\n",
    "spacing = 3\n",
    "\n",
    "skipped = getSkippedSlides(skip_slides)\n",
    "\n",
    "#Convert slides to text and pictures\n",
    "text, pictures = getContent(filename, language, skipped, spacing)\n",
    "\n",
    "#Generate summary\n",
    "summary = summarize_text(text, test=False)\n",
    "\n",
    "#Generate pdf\n",
    "createPDF(filename=newfile, lang=language, header=header, text=summary, imagefiles=pictures)\n",
    "\n",
    "print(\"The\", header, \"notes were saved to file\", newfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
